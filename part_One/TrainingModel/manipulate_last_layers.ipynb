{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "expecting to import googleNet model",
   "id": "c62d04490bf43251"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "# import model from path\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "model = models.googlenet(pretrained=True)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer=SGD(model.parameters(),lr=0.001)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 4)\n",
    ")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from path import train_l , X_train , y_train , y_test ,X_test\n",
    "import keras\n",
    "import torch\n",
    "import time\n",
    "start = time.time()\n",
    "EPOCHS =  25\n",
    "for epoch in range( EPOCHS) :\n",
    "    # TRAIN  MODEL\n",
    "    model.train()\n",
    "\n",
    "    #INITIALIZE THE LOSS BY 0\n",
    "    loss = 0.00\n",
    "\n",
    "    for X_l  , y_l in train_l:\n",
    "\n",
    "        optimizer.zero_grad() # clear the gradients from the previous step\n",
    "        y_pred = model(X_l) # get the prediction values\n",
    "        l = loss_fn(y_pred,y_l) # calculate the loss\n",
    "        l.backward() # execute the backpropagation\n",
    "        optimizer.step() # adjust the weights (parameters)\n",
    "        loss += l.item() * len(X_l)\n",
    "    loss_epoch = loss/len(X_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Temps total d'entraînement :\", (end - start)/60, \"minutes\")"
   ],
   "id": "bebba534b64a5080"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "with torch.no_grad() :\n",
    "    # get the final learned weight\n",
    "    weigth = model.linear.weigth.item()\n",
    "    bias = model.linear.bias.item()"
   ],
   "id": "42440bd6bcc2240f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(\"\\nGénération des prédictions pour la matrice de confusion...\")\n",
    "y_pred = model.predict(X_test, batch_size=32)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1) if len(y_test.shape) > 1 else y_test\n",
    "\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Count'})\n",
    "plt.title('Matrice de Confusion', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('Classe Réelle', fontsize=12)\n",
    "plt.xlabel('Classe Prédite', fontsize=12)"
   ],
   "id": "a2c5de1d04c1e0e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "# saving the model\n",
    "PATH = '../../models/model-'+time.localtime()+'.pth'\n",
    "# get all the learned parameters\n",
    "model_weights = model.state_dict()\n",
    "torch.save(model_weights,PATH)"
   ],
   "id": "3fe15c70d4b7d567"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
